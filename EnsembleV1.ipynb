{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 小环境/猪群舒适度指标体系\n",
    "## 第一阶段：\n",
    "#### 环控参数-->猪群舒适度（处方笺咳嗽/腹泻）\n",
    "\n",
    "从温度、湿度、喷淋、风量等环境参数中，结合猪群自身因素和时间变量，总结提取影响猪群健康和舒适度（造成咳嗽/腹泻）的关键环境因素。"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "按批次取数：\n",
    "STEP1:\n",
    "取10月结算的批次信息，字段：厂区号ffieldno、单元号unit、批次号batchno、日龄age、转入数量ingoodqty、转入不合格数inbadqty、\n",
    "转出数量outqty、转出不合格数outbadqty、转入日龄indayold、转出日龄outdayold、初均重staravgweight、末均重endavgweight。\n",
    "-> \n",
    "STEP2:\n",
    "根据以上的信息匹配环控数据，将每天的环控数据转化为指标\n",
    "指标暂设：日间为8：00-20：00，夜间为20：00-次日8：00\n",
    "日间温度day_temp  夜间温度night_temp  日间喷淋day_shower 夜间喷淋night_shower\n",
    "每个指标包含max,min,mean,std，其中max和min为了去掉离群点分别采用0.9quantile和0.1quantile\n",
    "共16个变量\n",
    "->\n",
    "STEP3:\n",
    "做好的环控数据，与第一部的批次数据进行匹配\n",
    "->\n",
    "STEP4:\n",
    "取处方笺中的疾病数据，筛选条件是'咳嗽'/'腹泻' in hxd_symptom，只取时间、批次信息\n",
    "->\n",
    "STEP5:\n",
    "根据时间、批次，给处理好的环控数据打上标签\n",
    "->\n",
    "STEP6:\n",
    "构建时间窗口，统计分析，特征筛选，提取重要特征，模型检验"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 星环/环控数据库取数、数据聚合 （时间较久，一个月数据大概需要8小时）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# import re\n",
    "# from pyhive import hive\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import requests\n",
    "# import json\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "# sys.path.append('/data/datamining/envir/Py_functions')\n",
    "# from get_data.get_data_func import * ##取数function\n",
    "# ## 保育信息表去批次信息\n",
    "# df = query_data(method ='inceptor', username = 'szhuangdancheng', password = '2020@hdc',\n",
    "#            sql = '''SELECT BatchNO,InDate,OutDate,InGoodQty,InBadQty,OutQty,OutBadQty,InDayOld,OutDayOld,StarAvgWeight,EndAvgWeight   \n",
    "#            FROM mydw.source_my_sc_consalary \n",
    "#            where date(outdate) between '20201001' and '20201030' ''').drop_duplicates()\n",
    "# batchlist = tuple(df.batchno.unique())\n",
    "\n",
    "# raw_field = query_data(method ='inceptor', username = 'szhuangdancheng', password = '2020@hdc',\n",
    "#            sql = '''SELECT fbatchno,ffieldid,funitnames as unit\n",
    "#            FROM mydw.source_my_sc_pigbatch \n",
    "#            where fbatchno in ''' + str(batchlist))\n",
    "\n",
    "# def expand_unit(df):  # 批次信息的处理 —— 1.识别单元号 2.将不同单元拆分成不同的记录\n",
    "#     df['unit'] = df.unit.apply(lambda x: re.findall(r'\\d+', x))\n",
    "#     res = []\n",
    "#     for i in range(df.shape[0]):\n",
    "#         temp = df.iloc[i,:]\n",
    "#         for j in temp['unit']:\n",
    "#             cand = dict(temp)\n",
    "#             cand['unit'] = j\n",
    "#             res.append(cand)\n",
    "#     return pd.DataFrame(res)\n",
    "# field = expand_unit(raw_field)\n",
    "\n",
    "# batch_info = pd.merge(field,df,left_on = 'fbatchno', right_on = 'batchno', how = 'outer').drop('fbatchno',axis = 1)\n",
    "# unit = pd.read_csv('unit.csv').rename({'field_id':'ffieldid'},axis = 1).astype({'unit':'str'})\n",
    "# step_2_data = unit.merge(batch_info,on = ['ffieldid','unit'],how = 'inner').astype({'indate':'datetime64','outdate':'datetime64'})\n",
    "\n",
    "# def data_mani(dic,size = '10min'): # 按照基础信息，匹配环控数据并对其进行数据处理\n",
    "#     env_data = search_data(UnitID = dic['id'],Size = 999999,StartTime = str(dic['indate']), LimitTime = str(dic['outdate'])) \n",
    "    \n",
    "#     #读取环控数据，若该单元没有环控数据，则返回None\n",
    "#     try:\n",
    "#         if env_data.shape[0] == 0: \n",
    "#             print('没有环控数据 : ' +dic['id'] )\n",
    "#             return None\n",
    "#     except:\n",
    "#         print(\"环控数据报错: \"+dic['id'])\n",
    "#         return None\n",
    "#     env_data = env_data.applymap(lambda x: 0 if x =='' else x).fillna(method = 'ffill')\n",
    "#     env_data = env_data.astype({'time':'datetime64','shower_1_acc_uptime':'int','shower_2_acc_uptime':'int'}).set_index('time')\n",
    "    \n",
    "#     #temperature：室内两个温度传感器的平均值，然后以size为最小时间粒度做聚合求平均，默认10min\n",
    "#     raw_temp = env_data[['temperature_inner_1','temperature_inner_2']]\n",
    "#     raw_temp['temperature_inner_1'] = raw_temp.apply(lambda x: x.temperature_inner_2 if (x.temperature_inner_1<5)|(x.temperature_inner_1>40) \n",
    "#                                                      else x.temperature_inner_1, axis = 1)\n",
    "#     raw_temp = raw_temp[(raw_temp.temperature_inner_1 >0)&(raw_temp.temperature_inner_1 <40)]\n",
    "#     raw_temp['temperature_inner_2'] = raw_temp.apply(lambda x: x.temperature_inner_1 if (x.temperature_inner_2<5)|(x.temperature_inner_2>40)\n",
    "#                                                      else x.temperature_inner_2, axis = 1)\n",
    "#     temperature = raw_temp.resample(size).mean().apply(lambda x: x.temperature_inner_1/2+x.temperature_inner_2/2,axis = 1)    \n",
    "    \n",
    "#     #shower：室内两个喷淋设备的开启时间，以size为最小单位时间，两个设备单位时间内开启的累计时长加和，size默认10min\n",
    "#     shower = (env_data.resample(size).max() - env_data.resample(size).min()).apply(lambda x: x.shower_1_acc_uptime + x.shower_2_acc_uptime, axis = 1 )\n",
    "\n",
    "#     #区分日间夜间，早8-晚8为日间，此外为夜间。 温度和喷淋均区分日间夜间情况\n",
    "#     raw_temp_day = temperature[(temperature.index.hour >=8) & (temperature.index.hour<20)]\n",
    "#     raw_temp_night = temperature[(temperature.index.hour <8) | (temperature.index.hour>=20)]\n",
    "#     raw_shower_day = shower[(shower.index.hour >=8) & (shower.index.hour < 20)]\n",
    "#     raw_shower_night = shower[(shower.index.hour <8) | (shower.index.hour>=20)]\n",
    "#     diminished_data = []\n",
    "    \n",
    "#     #分别计算日/夜间的温度/喷淋数据的四个指标：max,min,mean,std\n",
    "#     diminished_data.append(raw_temp_day.groupby(raw_temp_day.index.date).quantile(0.9))\n",
    "#     diminished_data.append(raw_temp_day.groupby(raw_temp_day.index.date).quantile(0.1))\n",
    "#     diminished_data.append(raw_temp_day.groupby(raw_temp_day.index.date).mean())\n",
    "#     diminished_data.append(raw_temp_day.groupby(raw_temp_day.index.date).std())\n",
    "#     diminished_data.append(raw_temp_night.groupby(raw_temp_night.index.date).quantile(0.9))\n",
    "#     diminished_data.append(raw_temp_night.groupby(raw_temp_night.index.date).quantile(0.1))\n",
    "#     diminished_data.append(raw_temp_night.groupby(raw_temp_night.index.date).mean())\n",
    "#     diminished_data.append(raw_temp_night.groupby(raw_temp_night.index.date).std())\n",
    "#     diminished_data.append(raw_shower_day.groupby(raw_shower_day.index.date).quantile(0.9))\n",
    "#     diminished_data.append(raw_shower_day.groupby(raw_shower_day.index.date).quantile(0.1))\n",
    "#     diminished_data.append(raw_shower_day.groupby(raw_shower_day.index.date).mean())\n",
    "#     diminished_data.append(raw_shower_day.groupby(raw_shower_day.index.date).std())\n",
    "#     diminished_data.append(raw_shower_night.groupby(raw_shower_night.index.date).quantile(0.9))\n",
    "#     diminished_data.append(raw_shower_night.groupby(raw_shower_night.index.date).quantile(0.1))\n",
    "#     diminished_data.append(raw_shower_night.groupby(raw_shower_night.index.date).mean())\n",
    "#     diminished_data.append(raw_shower_night.groupby(raw_shower_night.index.date).std())\n",
    "#     diminished_data = pd.concat(diminished_data,axis = 1).reset_index()\n",
    "#     var_name = ['day_temp_max','day_temp_min','day_temp_mean','day_temp_std',\n",
    "#                               'night_temp_max','night_temp_min','night_temp_mean','night_temp_std',\n",
    "#                               'day_shower_max','day_shower_min','day_shower_mean','day_shower_std',\n",
    "#                               'night_shower_max','night_shower_min','night_shower_mean','night_shower_std']\n",
    "#     diminished_data.columns = ['time'] + var_name\n",
    "    \n",
    "#     #添加基础信息，包括批次号、日龄、厂区号、单元、转入猪头数、转入病弱猪头数、转出猪头数，转出病弱猪头数\n",
    "#     diminished_data['batchno'] = dic['batchno']\n",
    "#     diminished_data['age'] = (diminished_data.time - step_2_data.astype({'indate':'datetime64'}).iloc[0,4].date()).apply(lambda x: x.days)\n",
    "#     diminished_data['age'] += int(round(dic['indayold']))\n",
    "#     diminished_data['ffieldid'] = dic['ffieldid']\n",
    "#     diminished_data['unit'] = dic['unit']\n",
    "#     diminished_data['ingoodqty'] = dic['ingoodqty']\n",
    "#     diminished_data['inbadqty'] = dic['inbadqty']\n",
    "#     diminished_data['outqty'] = dic['outqty']\n",
    "#     diminished_data['outbadqty'] = dic['outbadqty']\n",
    "#     diminished_data['indayold'] = dic['indayold']\n",
    "#     diminished_data['outdayold'] = dic['outdayold']\n",
    "#     diminished_data['staravgweight'] = dic['staravgweight']\n",
    "#     diminished_data['endavgweight'] = dic['endavgweight']\n",
    "#     diminished_data = diminished_data[['time','batchno','ffieldid','unit','age','ingoodqty','inbadqty','outqty','outbadqty','indayold','outdayold','staravgweight','endavgweight'] + var_name]\n",
    "#     return diminished_data \n",
    "\n",
    "# step_3_data = []\n",
    "# for i in range(10):\n",
    "#     print('current progress: '+ str(i+1)+'/'+ str(step_2_data.shape[0]))\n",
    "#     try:\n",
    "#         step_3_data.append(data_mani(dict(step_2_data.iloc[i,:])))\n",
    "#     except:\n",
    "#         print('存在环控，但数据异常',dict(step_2_data.iloc[i,:])['id'])\n",
    "# step_3_data = pd.concat(step_3_data,axis = 0)\n",
    "\n",
    "# step_3_data.to_csv('result_step3_OCT_beta1.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "## 处方笺提取/时间窗口建立"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import sys\n",
    "from pyhive import hive\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None) #显示所有列\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "sys.path.append('/data/datamining/envir/Py_functions')\n",
    "from get_data.get_data_func import * ##取数function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 建立时间窗口\n",
    "data = pd.read_csv('result_step3_OCT_beta1.csv').astype({'time':'datetime64'})\n",
    "## 创建unique id \n",
    "data['id'] = data.apply(lambda x: str(x.ffieldid)+'/'+str(x.unit) + '/' + str(x.batchno)[:5],axis = 1)\n",
    "## 删去异常值\n",
    "data = data[(data.day_temp_max <= 40)\n",
    "                        & (data.day_temp_min > 10) &\n",
    "                        (data.night_temp_max <= 40) &\n",
    "                        (data.night_temp_min > 10) &\n",
    "                        (data.day_shower_max < 7200) &\n",
    "                        (data.night_shower_max < 7200)]\n",
    "## 删去重复值\n",
    "data = data.drop_duplicates(['time','id']).reset_index(drop = True)\n",
    "## 环控参数\n",
    "prop =  ['day_temp_max', 'day_temp_min', 'day_temp_mean','day_temp_std', \n",
    "         'night_temp_max', 'night_temp_min', 'night_temp_mean', 'night_temp_std',\n",
    "         'day_shower_max','day_shower_min', 'day_shower_mean', 'day_shower_std',\n",
    "       'night_shower_max', 'night_shower_min', 'night_shower_mean','night_shower_std']\n",
    "## 创建时间窗口\n",
    "def addsuffix(lst,s):\n",
    "    res = []\n",
    "    for i in list(lst):\n",
    "        res.append(i + s)\n",
    "    return res\n",
    "## 前3天时间窗口建立\n",
    "data_pre1 = data.copy()\n",
    "data_pre1.time = data.time + dt.timedelta(1)\n",
    "tm1 = data[['time','id']].merge(data_pre1,how = 'left',on = ['time','id'])[prop]\n",
    "tm1.columns = addsuffix(tm1[prop].columns,'_tm1')\n",
    "data_pre2 = data.copy()\n",
    "data_pre2.time = data.time + dt.timedelta(2)\n",
    "tm2 = data[['time','id']].merge(data_pre2,how = 'left',on = ['time','id'])[prop]\n",
    "tm2.columns = addsuffix(tm2[prop].columns,'_tm2')\n",
    "data_pre3 = data.copy()\n",
    "data_pre3.time = data.time + dt.timedelta(3)\n",
    "tm3 = data[['time','id']].merge(data_pre3, how = 'left',on = ['time','id'])[prop]\n",
    "tm3.columns = addsuffix(tm3[prop].columns,'_tm3')\n",
    "## concat\n",
    "data = pd.concat([data,tm1,tm2,tm3],axis = 1)\n",
    "## 温度变化指标\n",
    "data['daychange']= data.day_temp_mean - data.day_temp_mean_tm1 ##相比昨天日间温度变化\n",
    "data['nightchange'] = data.night_temp_mean - data.night_temp_mean_tm1 ##相比昨天夜间温度变化\n",
    "data['dailychange'] = data.day_temp_max - data.night_temp_min ##昼夜温差\n",
    "## 绝对值\n",
    "data['daychange_abs'] = data.daychange.apply(np.abs)\n",
    "data['nightchange_abs'] = data.nightchange.apply(np.abs)\n",
    "data['dailychange_abs'] = data.dailychange.apply(np.abs)\n",
    "\n",
    "## 剔除nan值\n",
    "data = data.dropna()\n",
    "\n",
    "## 提取咳嗽标签\n",
    "batchlist  = tuple(data.batchno.unique())\n",
    "cough = query_data(method ='inceptor', username = 'szhuangdancheng', password = '2020@hdc',\n",
    "           sql = '''SELECT date(attack_date) AS `date`,batchno,ffieldid,unit_no\n",
    "                    FROM mydw.source_my_sc_recipe AS re \n",
    "                    INNER JOIN mydw.source_my_sc_cfq_appy_sympto neo\n",
    "                    ON neo.my_recipeid = re.id\n",
    "                    WHERE segmentid = 13906\n",
    "                    AND hxd_sympto LIKE '%咳嗽%' AND batchno in ''' + str(batchlist))\n",
    "cough['cough'] = 1\n",
    "cough = cough.astype({'unit_no':'int'}).rename({'date':'time','unit_no':'unit'},axis = 1).astype({'time':'datetime64'})\n",
    "\n",
    "## 提取腹泻标签\n",
    "diarrhea = query_data(method ='inceptor', username = 'szhuangdancheng', password = '2020@hdc',\n",
    "           sql = '''SELECT date(attack_date) AS `date`,batchno,ffieldid,unit_no\n",
    "                    FROM mydw.source_my_sc_recipe AS re \n",
    "                    INNER JOIN mydw.source_my_sc_cfq_appy_sympto neo\n",
    "                    ON neo.my_recipeid = re.id\n",
    "                    WHERE segmentid = 13906\n",
    "                    AND fmw_sympto LIKE '%腹泻%' AND batchno in ''' + str(batchlist))\n",
    "diarrhea['diarrhea'] = 1\n",
    "diarrhea = diarrhea.astype({'unit_no':'int'}).rename({'date':'time','unit_no':'unit'},axis = 1).astype({'time':'datetime64'})\n",
    "\n",
    "## 数据融合\n",
    "final_data = data.merge(cough,how = 'left',on = ['time','batchno','ffieldid','unit'])\n",
    "final_data = final_data.merge(diarrhea,how = 'left',on = ['time','batchno','ffieldid','unit'])\n",
    "final_data.diarrhea.fillna(0,inplace = True)\n",
    "final_data.cough.fillna(0,inplace = True)\n",
    "final_data.to_csv('final_data10.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据清洗/EDA/特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import sys\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None) #显示所有列bb\n",
    "# pd.set_option('display.max_rows', None) #显示所有列bb\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "def addsuffix(lst,s):\n",
    "    res = []\n",
    "    for i in list(lst):\n",
    "        res.append(i + s)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据读取\n",
    "数据情况：\n",
    "共87659条以天、单元为最小单位的数据，包含1829个单元, 1113个批次, 169个厂区。\n",
    "时间从2020年8月1日到10月31日。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 数据读取\n",
    "df = pd.read_csv('final_data10.csv')\n",
    "## 时间选取\n",
    "df = df[df.time > '2020-08-01'].astype({'ffieldid':'str','cough' : 'int', 'diarrhea' : 'int'}).reset_index(drop = True)\n",
    "## 日龄，猪群数量分段\n",
    "df.age = (df.age//10)*10\n",
    "df.inbadqty = np.round((df.inbadqty/(df.ingoodqty+df.inbadqty))*100,1)\n",
    "df.ingoodqty = df.ingoodqty//100*100 \n",
    "## 猪群转入指数 = 初均重/转入日龄 ：相同日龄转入，越重的猪越好\n",
    "df['in_index'] = df.staravgweight/df.indayold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 变量筛选 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 字段分类\n",
    "key = ['time','id']\n",
    "## 猪群变量\n",
    "batch_var = ['batchno', 'ffieldid', 'unit', 'age', 'ingoodqty', 'inbadqty',\n",
    "       'outqty', 'outbadqty', 'indayold', 'outdayold', 'staravgweight','endavgweight','in_index' ]\n",
    "## 环控变量\n",
    "env =  ['day_temp_max', 'day_temp_min', 'day_temp_mean','day_temp_std', \n",
    "         'night_temp_max', 'night_temp_min', 'night_temp_mean', 'night_temp_std',\n",
    "         'day_shower_max','day_shower_min', 'day_shower_mean', 'day_shower_std',\n",
    "       'night_shower_max', 'night_shower_min', 'night_shower_mean','night_shower_std']\n",
    "# 创建时间窗口\n",
    "env_tm1 = addsuffix(env,'_tm1')\n",
    "env_tm2 = addsuffix(env,'_tm2')\n",
    "env_tm3 = addsuffix(env,'_tm3')\n",
    "# 变化变量\n",
    "change = ['daychange','nightchange','dailychange','daychange_abs','nightchange_abs','dailychange_abs']\n",
    "# 合并\n",
    "env_var = env.copy()\n",
    "env_var.extend(env_tm1)\n",
    "env_var.extend(env_tm2)\n",
    "env_var.extend(env_tm3)\n",
    "env_var.extend(change)\n",
    "## 标签\n",
    "label = ['cough','diarrhea']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 人工筛选、根据定义和相关性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 根据X,Y之间相关性进行筛选，pearsonr不适用与二分类标签\n",
    "from scipy.stats import pearsonr\n",
    "def print_corr(var_name):\n",
    "    for i in var_name:\n",
    "        try:\n",
    "            c,p = pearsonr(df[i],df.cough)[0],pearsonr(df[i],df.cough)[1]\n",
    "            print(i + ':  Corr: '+ str(c)+ ' p-value: ' + str(p))\n",
    "        except:\n",
    "            print(i + ': Not applicable')\n",
    "# print_corr(env_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "筛选后变量剩余：  44\n"
     ]
    }
   ],
   "source": [
    "## 根据变量之间相关性选取变量\n",
    "# df.corr\n",
    "## 猪群变量\n",
    "batch_var_selected = ['ffieldid', 'age', 'ingoodqty', 'inbadqty','indayold', 'staravgweight','in_index']\n",
    "# df[batch_var_selected].corr()\n",
    "## 环控变量\n",
    "prop = ['day_temp_mean','day_temp_std','night_temp_mean','night_temp_std',\n",
    "                'day_shower_max','day_shower_std','night_shower_max','night_shower_std']\n",
    "## 时间变量\n",
    "prop_tm1 = addsuffix(prop,'_tm1')\n",
    "prop_tm2 = addsuffix(prop,'_tm2')\n",
    "prop_tm3 = addsuffix(prop,'_tm3')\n",
    "## 变化变量\n",
    "change = ['daychange','nightchange','dailychange','daychange_abs','nightchange_abs']\n",
    "env_var_selected = prop.copy()\n",
    "env_var_selected.extend(prop_tm1)\n",
    "env_var_selected.extend(prop_tm2)\n",
    "env_var_selected.extend(prop_tm3)\n",
    "env_var_selected.extend(change)\n",
    "# df[env_var_selected].corr().to_csv('corr2.csv')\n",
    "val_selected = []\n",
    "val_selected.extend(batch_var_selected)\n",
    "val_selected.extend(env_var_selected)\n",
    "print('筛选后变量剩余： ', len(val_selected))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 基于模型筛选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "X = df[val_selected]\n",
    "y = df.cough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87659, 38)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.82738941, 0.82738941, 0.82741782, 0.82733593, 0.8274082 ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 基于linearSVC模型筛选\n",
    "from sklearn.feature_selection import  SelectFromModel\n",
    "from sklearn.svm import  LinearSVC\n",
    "mod=LinearSVC(C=0.1, penalty=\"l1\", dual=False).fit(X,y)\n",
    "selectmod=SelectFromModel(mod, prefit=True)\n",
    "selectmod.transform(X)\n",
    "cols = selectmod.get_support(indices = True)\n",
    "X_selected_svm = X.iloc[:,cols]\n",
    "print(X_selected_svm.shape)\n",
    "clf = LinearSVC(C=0.1, penalty=\"l1\", dual=False)\n",
    "cross_val_score(clf, X_selected_svm, y, cv=5, scoring='f1_weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 基于SVC模型筛选 (非线性核，时间较长)\n",
    "# from sklearn.feature_selection import  SelectFromModel\n",
    "# from sklearn.svm import SVC\n",
    "# mod=SVC(C=0.1,kernel = 'rbf',class_weight = 'balanced',max_iter = 10).fit(X,y)\n",
    "# selectmod=SelectFromModel(mod, prefit=True)\n",
    "# selectmod.transform(X)\n",
    "# cols = selectmod.get_support(indices = True)\n",
    "# X_selected_svm = X.iloc[:,cols]\n",
    "# print(X_selected_svm.shape)\n",
    "# clf = SVC(C=0.1,kernel = 'rbf',class_weight = 'balanced',max_iter = 10)\n",
    "# cross_val_score(clf, X_selected_svm, y, cv=5, scoring='f1_macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87659, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.82741782, 0.82749998, 0.82738941, 0.82733593, 0.82597918])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 基于GBDT模型筛选\n",
    "from sklearn.ensemble import  GradientBoostingClassifier\n",
    "gb=GradientBoostingClassifier()\n",
    "selectmod = SelectFromModel(gb)\n",
    "selectmod.fit_transform(X,y)\n",
    "cols = selectmod.get_support(indices = True)\n",
    "X_selected_gbdt = X.iloc[:,cols]\n",
    "print(X_selected_gbdt.shape)\n",
    "clf = GradientBoostingClassifier()\n",
    "cross_val_score(clf, X_selected_gbdt, y, cv=5, scoring='f1_weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 基于逻辑回归模型筛选\n",
    "from sklearn.linear_model import  LogisticRegressionCV\n",
    "lrmodel=LogisticRegressionCV(penalty='l1',solver='liblinear')\n",
    "selectmod=SelectFromModel(lrmodel,threshold=10)\n",
    "selectmod.fit(X,y)\n",
    "selectmod.transform(X)\n",
    "cols = selectmod.get_support(indices = True)\n",
    "X_selected = X.iloc[:,cols]\n",
    "X_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87659, 27)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.82785901, 0.82878064, 0.82901369, 0.82826583, 0.83082738])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 基于树模型筛选\n",
    "from sklearn.ensemble import  ExtraTreesClassifier\n",
    "tree=ExtraTreesClassifier().fit(X,y)\n",
    "selectmod = SelectFromModel(tree,prefit=True)\n",
    "selectmod.transform(X)\n",
    "cols = selectmod.get_support(indices = True)\n",
    "X_selected_tree = X.iloc[:,cols]\n",
    "print(X_selected_tree.shape)\n",
    "clf = ExtraTreesClassifier()\n",
    "cross_val_score(clf, X_selected_tree, y, cv=5, scoring='f1_weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 卡方检验选择\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "## 选择k个与自变量卡方相关系数最高的特征，适用于无序分类变量之间的相关性分析\n",
    "selector = SelectKBest(chi2, k=3)\n",
    "## X必须为正数\n",
    "selector.fit_transform(X.iloc[:,:7], y)\n",
    "cols = selector.get_support(indices = True)\n",
    "X_selected_chi2 = X.iloc[:,:7].iloc[:,cols]\n",
    "X_selected_chi2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ffieldid', 'age', 'ingoodqty', 'indayold', 'staravgweight', 'in_index',\n",
       "       'day_temp_mean', 'night_temp_mean', 'day_temp_mean_tm1',\n",
       "       'day_temp_mean_tm2', 'day_temp_std_tm2', 'nightchange', 'dailychange'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_selected_gbdt.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree # 引入tree模型\n",
    "import pydotplus  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.22586126, 0.53320798, 0.4326619 , 0.42151899, 0.51574703])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(random_state=0, max_depth = 10, splitter = 'random', min_samples_leaf = 5, class_weight = 'balanced' )# 引入模型\n",
    "clf = clf.fit(X_selected_gbdt, y) # 训练模型\n",
    "\n",
    "# 可视化树，输出为pdf格式\n",
    "dot_data = tree.export_graphviz(clf, out_file=None) \n",
    "graph = pydotplus.graph_from_dot_data(dot_data) \n",
    "graph.write_pdf(\"tree.pdf\") \n",
    "clf = tree.DecisionTreeClassifier(random_state=0, max_depth = 5, splitter = 'random', min_samples_leaf = 5, class_weight = 'balanced' )# 引入模型\n",
    "cross_val_score(clf, X_selected_gbdt, y, cv=5,scoring='f1_weighted')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
